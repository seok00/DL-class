/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:445: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.
  rank_zero_deprecation(
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/usr/local/lib/python3.9/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/notebooks/checkpoints/{epoch:d} exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
  | Name  | Type       | Params
-------------------------------------
0 | model | Sequential | 55.3 K
-------------------------------------
55.3 K    Trainable params
0         Non-trainable params
55.3 K    Total params
0.221     Total estimated model params size (MB)
/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(



Epoch 0:  88%|████████████████████████████████████████████████████████████████████████████████████████████████▋             | 1648/1876 [00:07<00:01, 221.95it/s, loss=0.2, v_num=z18t]




Epoch 1:  90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏            | 1680/1876 [00:07<00:00, 229.22it/s, loss=0.127, v_num=z18t]




Epoch 2:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 1689/1876 [00:07<00:00, 227.04it/s, loss=0.0638, v_num=z18t]




Epoch 3:  87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                | 1630/1876 [00:07<00:01, 218.80it/s, loss=0.0698, v_num=z18t]




Epoch 4:  82%|███████████████████████████████████████████████████████████████████████████████████████████████████▍                      | 1530/1876 [00:07<00:01, 213.69it/s, loss=0.0449, v_num=z18t]




Epoch 5:  79%|████████████████████████████████████████████████████████████████████████████████████████████████                          | 1478/1876 [00:06<00:01, 219.79it/s, loss=0.0435, v_num=z18t]





Epoch 6: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1876/1876 [00:08<00:00, 214.00it/s, loss=0.0403, v_num=z18t]




Epoch 7:  84%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                   | 1583/1876 [00:07<00:01, 210.80it/s, loss=0.039, v_num=z18t]




Epoch 8:  79%|████████████████████████████████████████████████████████████████████████████████████████████████                          | 1478/1876 [00:06<00:01, 215.24it/s, loss=0.0243, v_num=z18t]




Epoch 9: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1876/1876 [00:08<00:00, 221.17it/s, loss=0.0425, v_num=z18t]
Testing DataLoader 0:  12%|█████████████████                                                                                                                        | 39/313 [00:00<00:00, 386.69it/s]
Epoch 9, global step 17190: 'val_acc' reached 0.97080 (best 0.97080), saving model to '/home/notebooks/checkpoints/{epoch:d}/epoch=9-step=17190.ckpt' as top 5
`Trainer.fit` stopped: `max_epochs=10` reached.
/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/trainer.py:1385: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.
  rank_zero_warn(
Restoring states from the checkpoint path at /home/notebooks/checkpoints/{epoch:d}/epoch=9-step=17190.ckpt
Loaded model weights from checkpoint at /home/notebooks/checkpoints/{epoch:d}/epoch=9-step=17190.ckpt
/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
Testing DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:00<00:00, 401.52it/s]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m        Test metric        [22m┃[1m       DataLoader 0        [22m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m         test_acc          [39m│[35m    0.9735999703407288     [39m│
│[36m         test_loss         [39m│[35m    0.10926489531993866    [39m│
