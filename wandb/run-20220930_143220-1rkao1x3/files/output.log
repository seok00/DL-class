
Sanity Checking DataLoader 0:   0%|                                                                                                                                             | 0/2 [00:00<?, ?it/s]
/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:445: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.
  rank_zero_deprecation(
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/usr/local/lib/python3.9/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/notebooks/checkpoints/{epoch:d} exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
  | Name    | Type      | Params
--------------------------------------
0 | layer_1 | Conv2d    | 224
1 | layer_2 | Conv2d    | 224
2 | layer_3 | Conv2d    | 224
3 | maxpool | MaxPool2d | 0
4 | relu    | ReLU      | 0
5 | flatten | Flatten   | 0
6 | fc1     | Linear    | 16.5 K
7 | fc2     | Linear    | 1.3 K
--------------------------------------
18.5 K    Trainable params
0         Non-trainable params
18.5 K    Total params
0.074     Total estimated model params size (MB)
/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
